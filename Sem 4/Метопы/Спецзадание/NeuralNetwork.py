# Импортируем необходимые функции и библиотеки из библиотеки numpy.
# exp(x) = e^x
# dot - матричное перемножение
# random - генерация случайных чисел
# array - создание массива
from numpy import exp, array, random, dot

class NeuralNetwork():
    def __init__(self):
        self.weights = None

    def train_model(self):
        # Задаем входные данные для обучающего набора. 
        # Каждый элемент - набор значений подаваемый "на вход" нейронов
        training_set_inputs = array([[0, 0, 1], [1, 1, 1], [1, 0, 1], [0, 1, 1]])

        # Задаем ожидаемые выходные данные для обучающего набора. 
        # Каждый элемент соответствует ожидаемому выходному значению для соответсвенного набора данных выше.
        training_set_outputs = array([[0, 1, 1, 0]]).T

        # Инициализируем веса случайными значениями в диапазоне [-1, 1]. Матрица размерности (3, 1) для соответствия входам.
        synaptic_weights = 2 * random.random((3, 1)) - 1

        # Начинаем цикл обучения нейронной сети, который повторяется 10,000 раз.
        for _ in range(10000):

            # Получаем результат для текущих весов
            # output - результат работы нейронной сети
            # output = 1 / 1 + e^(-(w1*x1 + w2*x2 + w3*x3))
            # Где w - вес
            # x - входной нейрон
            output = 1 / (1 + exp(-(dot(training_set_inputs, synaptic_weights))))

            # Вычисляем ошибку обучения, учитывая ожидаемый выход, текущий выход и градиент функции активации.
            # Используем градиентный спуск для корректировки весов.
            # error = (ожидаемый выход - текущий выход) * текущий выход * (1 - текущий выход)
            synaptic_weights += dot(training_set_inputs.T, (training_set_outputs - output) * output * (1 - output))
        
        self.weights = synaptic_weights

    def predict(self, input):
        return 1 / (1 + exp(-(dot(input, self.weights))))
